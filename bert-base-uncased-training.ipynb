{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remember that the We already provide a version that done fine tuning, if you want to check it , just use the all the output dir instead of doing the finetuning on original BERT!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-12T13:11:12.925418Z",
     "iopub.status.busy": "2021-12-12T13:11:12.924559Z",
     "iopub.status.idle": "2021-12-12T13:11:49.625206Z",
     "shell.execute_reply": "2021-12-12T13:11:49.624078Z",
     "shell.execute_reply.started": "2021-12-12T13:11:12.925365Z"
    },
    "id": "3FV_K9OsdJID",
    "outputId": "f2fd35a2-46cb-47b2-a007-52b55cc5f872",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!mkdir squad\n",
    "!wget https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json -O squad/train-v2.0.json\n",
    "!wget https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json -O squad/dev-v2.0.json\n",
    "!pip install transformers\n",
    "!pip install git+https://github.com/d2l-ai/d2l-zh@release  # installing d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-12T13:17:45.374766Z",
     "iopub.status.busy": "2021-12-12T13:17:45.374267Z",
     "iopub.status.idle": "2021-12-12T13:17:45.648449Z",
     "shell.execute_reply": "2021-12-12T13:17:45.647396Z",
     "shell.execute_reply.started": "2021-12-12T13:17:45.374722Z"
    },
    "id": "bz0a74DKZUzp"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qv5itiP2ikPq"
   },
   "source": [
    "From the preview of the dataset, we can easily see that, the whole dataset is a dataset with different values:\n",
    "1. The first two is the data and the version\n",
    "2. For each data we haveï¼š\n",
    "  1. title\n",
    "  2. a paragraph list\n",
    "3. For each paragraph list we haveï¼š\n",
    "  1. context(The given text)\n",
    "  2. qas(question and answering)\n",
    "4. For each qas:    \n",
    "  1. answers\n",
    "  2. id\n",
    "  3. question\n",
    "  4. is_impossible(if it can answer question)\n",
    "5. For each answers:     \n",
    "  1. have answer_start(The start of the answer)\n",
    "  2. text(the answering text)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v2r-QjvNkjvN"
   },
   "source": [
    "So, what we need is to out the context, which means a paragraph. Also, the question, text, answer start, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-12T13:12:21.034817Z",
     "iopub.status.busy": "2021-12-12T13:12:21.034545Z",
     "iopub.status.idle": "2021-12-12T13:12:21.045287Z",
     "shell.execute_reply": "2021-12-12T13:12:21.044156Z",
     "shell.execute_reply.started": "2021-12-12T13:12:21.034788Z"
    },
    "id": "eH-le-ZRdwd-"
   },
   "outputs": [],
   "source": [
    "#do the data preprocessing\n",
    "from pathlib import Path\n",
    "def preprocessing_and_read_dataset(path):\n",
    "  path = Path(path)\n",
    "  data_set = pd.read_json(path) \n",
    "  contexts = []\n",
    "  questions = []\n",
    "  answers = []\n",
    "  id_ = []\n",
    "  is_imp=[]\n",
    "  for article in data_set['data']:\n",
    "    paragraphs = article['paragraphs']\n",
    "    title = article['title']\n",
    "    for paragraph in paragraphs:\n",
    "      context = paragraph['context']\n",
    "      qas = paragraph['qas']\n",
    "      for text in qas:\n",
    "        q_id = text['id']\n",
    "        q_answer = text['answers']\n",
    "        q_isimp = text['is_impossible']\n",
    "        q_question = text['question']\n",
    "        #print(q_answer)\n",
    "        if q_answer == []:\n",
    "          contexts.append(context)\n",
    "          questions.append(q_question)\n",
    "          answers.append(ans)\n",
    "          id_.append(q_id)\n",
    "          is_imp.append(q_isimp)\n",
    "        else:\n",
    "            for ans in q_answer:\n",
    "              contexts.append(context)\n",
    "              questions.append(q_question)\n",
    "              answers.append(ans)\n",
    "              id_.append(q_id)\n",
    "              is_imp.append(q_isimp)\n",
    "  return contexts, questions, answers, id_, is_imp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h0lfeqT_2-zz"
   },
   "source": [
    "Read the training and validing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-12T13:12:22.338891Z",
     "iopub.status.busy": "2021-12-12T13:12:22.338554Z",
     "iopub.status.idle": "2021-12-12T13:12:23.863976Z",
     "shell.execute_reply": "2021-12-12T13:12:23.863312Z",
     "shell.execute_reply.started": "2021-12-12T13:12:22.338857Z"
    },
    "id": "SXsRk2ENz3hT"
   },
   "outputs": [],
   "source": [
    "train_contexts, train_questions, train_answers, train_id, train_isimp= preprocessing_and_read_dataset('squad/train-v2.0.json')\n",
    "valid_contexts, valid_questions, valid_answers, valid_id, valid_isimp = preprocessing_and_read_dataset('squad/dev-v2.0.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dcjn_RVH3WeD"
   },
   "source": [
    "Then, we need to add the ended index to our answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-12T13:12:23.865844Z",
     "iopub.status.busy": "2021-12-12T13:12:23.865243Z",
     "iopub.status.idle": "2021-12-12T13:12:23.983495Z",
     "shell.execute_reply": "2021-12-12T13:12:23.982415Z",
     "shell.execute_reply.started": "2021-12-12T13:12:23.865808Z"
    },
    "id": "jfjr415D3bB_"
   },
   "outputs": [],
   "source": [
    "def add_end_indices(answer, context):\n",
    "  '''\n",
    "  The given input is the answer dicitionary and corresponding context\n",
    "  '''\n",
    "  for a, ctext in zip(answer, context):\n",
    "    answer_text = a['text']\n",
    "    start_idx = a['answer_start']\n",
    "    end_idx = start_idx + len(answer_text)\n",
    "    # the readme file say that squad answers maybe off by a character or two, to fix this problem\n",
    "    if ctext[start_idx:end_idx] == answer_text:\n",
    "      a['answer_end'] = end_idx# add the end idx into it\n",
    "    elif ctext[start_idx-1:end_idx-1] == answer_text:\n",
    "      a['answer_end'] = end_idx-1\n",
    "      a['answer_start'] = start_idx-1\n",
    "    elif ctext[start_idx-2:end_idx-2] == answer_text:\n",
    "      a['answer_end'] = end_idx-2\n",
    "      a['answer_start'] = start_idx-2\n",
    "add_end_indices(train_answers,train_contexts)\n",
    "add_end_indices(valid_answers,valid_contexts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JMsiZBnluFcm"
   },
   "source": [
    "Then do the tokenize and trunctuating by using bert.\n",
    "Then we should add the special token into it, means [SEP], [CLS], [PAD] and so on.\n",
    "Since Bert has two constraints:     \n",
    "  1. All sentences must be padded or truncated to a single, fixed length.\n",
    "  2. The maximum sentence length. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remember that the We already provide a version that done fine tuning, if you want to check it , just use the all the output dir instead of doing the finetuning on original BERT! (You should specify a correct path on your own computer!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-12T13:16:45.566713Z",
     "iopub.status.busy": "2021-12-12T13:16:45.566376Z",
     "iopub.status.idle": "2021-12-12T13:16:45.655741Z",
     "shell.execute_reply": "2021-12-12T13:16:45.65476Z",
     "shell.execute_reply.started": "2021-12-12T13:16:45.566666Z"
    },
    "id": "tJ9G5R4w5htc"
   },
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "#out_dir = \"../input/model-parameters/model_pa/model_saved\"\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "#tokenizer = DistilBertTokenizerFast.from_pretrained(out_dir)\n",
    "training_encoding = tokenizer(train_contexts, train_questions, truncation=True, padding=True)#do the tokenize with padding and truncation\n",
    "validing_encoding = tokenizer(valid_contexts, valid_questions, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sC6zmv6CAvP8"
   },
   "source": [
    "Then we need to change the start index and end index to token start index and token end index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-12T02:51:57.234551Z",
     "iopub.status.busy": "2021-12-12T02:51:57.234305Z",
     "iopub.status.idle": "2021-12-12T02:51:57.961284Z",
     "shell.execute_reply": "2021-12-12T02:51:57.960583Z",
     "shell.execute_reply.started": "2021-12-12T02:51:57.234525Z"
    },
    "id": "OQdP6rtwA2nG"
   },
   "outputs": [],
   "source": [
    "def token_positions(encoding, answer):\n",
    "  start_position = []\n",
    "  end_position = []\n",
    "  for i in range(len(answer)):\n",
    "    #it will return the index of start token and end token\n",
    "    start_position.append(encoding.char_to_token(i, answer[i]['answer_start']))\n",
    "    end_position.append(encoding.char_to_token(i, answer[i]['answer_end']-1))\n",
    "    # if start position is none, answer has been truncated, then we assume it to the max_length\n",
    "    if start_position[-1] is None:\n",
    "      start_position[-1] = tokenizer.model_max_length\n",
    "    if end_position[-1] is None:\n",
    "      end_position[-1] = tokenizer.model_max_length\n",
    "  encoding.update({\"start_positions\": start_position, \"end_positions\": end_position})\n",
    "token_positions(training_encoding, train_answers)\n",
    "token_positions(validing_encoding, valid_answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FS4wCFyUIhic"
   },
   "source": [
    "Then we build the dataset from pytprch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-11T07:12:15.375151Z",
     "iopub.status.busy": "2021-12-11T07:12:15.374721Z",
     "iopub.status.idle": "2021-12-11T07:12:15.382368Z",
     "shell.execute_reply": "2021-12-11T07:12:15.381363Z",
     "shell.execute_reply.started": "2021-12-11T07:12:15.375118Z"
    },
    "id": "AInDDY-zH7dh"
   },
   "outputs": [],
   "source": [
    "class Squad_v2_Dataset(torch.utils.data.Dataset):\n",
    "  '''\n",
    "  We need to implement the __init__, __get__item and __len__ function\n",
    "  '''\n",
    "  def __init__(self, encoding):\n",
    "    self.encoding = encoding\n",
    "  def __getitem__(self, idx):\n",
    "    '''\n",
    "    given the idx, return the corresponding key-value pair\n",
    "    '''\n",
    "    dic = {}\n",
    "    for key, value in self.encoding.items():\n",
    "      dic[key] = torch.tensor(value[idx])\n",
    "    return dic\n",
    "  def __len__(self):\n",
    "    return len(self.encoding.input_ids)\n",
    "training_dataset = Squad_v2_Dataset(training_encoding)\n",
    "validing_dataset = Squad_v2_Dataset(validing_encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UyJWrQUVKUiU"
   },
   "source": [
    "Check the result of our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remember that the We already provide a version that done fine tuning, if you want to check it , just use the all the output dir instead of doing the finetuning on original BERT!(The same as previously), just remove the comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-12T13:17:12.15913Z",
     "iopub.status.busy": "2021-12-12T13:17:12.158598Z",
     "iopub.status.idle": "2021-12-12T13:17:20.024337Z",
     "shell.execute_reply": "2021-12-12T13:17:20.023212Z",
     "shell.execute_reply.started": "2021-12-12T13:17:12.159086Z"
    },
    "id": "LDkv8nGzJzyb",
    "outputId": "91f4a49e-e1d7-4056-8f1c-dbb411ae90d0"
   },
   "outputs": [],
   "source": [
    "from transformers import DistilBertForQuestionAnswering\n",
    "model = DistilBertForQuestionAnswering.from_pretrained('distilbert-base-uncased')\n",
    "# model = DistilBertForQuestionAnswering.from_pretrained(out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bNVUhLD6ndv5"
   },
   "source": [
    "Then we do the fine-tuning on our Squadv-2.0 Dataset with bert-large model, just add a dense layer in the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bJvHt7Ao47gc",
    "outputId": "c09e39ad-d4f4-42b6-b637-bb3b259828fe",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_iter = DataLoader(training_dataset, batch_size=16, shuffle=True)\n",
    "validing_iter = DataLoader(validing_dataset, batch_size=16, shuffle=False)\n",
    "next(iter(training_iter)), next(iter(validing_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vnWbZE2r4lHK"
   },
   "outputs": [],
   "source": [
    "from transformers import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy_gpu(net, data_iter, device=None):\n",
    "    '''\n",
    "    For test iter evaluate the accuracy\n",
    "    '''\n",
    "    #set to evaluation\n",
    "    net.eval()\n",
    "    if not device:\n",
    "        device = next(iter(net.parameters())).device\n",
    "    metric  = d2l.Accumulator(4)# validation loss,total correct num and total prediction\n",
    "    for batch in data_iter:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_pi = batch['start_positions'].to(device)\n",
    "        end_pi = batch['end_positions'].to(device)\n",
    "        outputs = net(input_ids, attention_mask=attention_mask, start_positions = start_pi,\n",
    "                        end_positions = end_pi)\n",
    "        loss = outputs[0]\n",
    "        start_logit = outputs.start_logits\n",
    "        end_logit = outputs.end_logits\n",
    "        metric.add(loss*input_ids.shape[0], d2l.accuracy(start_logit, start_pi),d2l.accuracy(end_logit,end_pi), input_ids.shape[0])\n",
    "    return metric[0]/metric[3], metric[1]/metric[3], metric[2]/metric[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-11T11:07:15.065378Z",
     "iopub.status.busy": "2021-12-11T11:07:15.065003Z",
     "iopub.status.idle": "2021-12-11T11:07:15.17473Z",
     "shell.execute_reply": "2021-12-11T11:07:15.173508Z",
     "shell.execute_reply.started": "2021-12-11T11:07:15.065284Z"
    },
    "id": "oWtkq8nH4Nx2",
    "outputId": "5009d6e3-68b9-432d-a309-c460cd666cd3"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "num_epoches = 50\n",
    "print(\"training on \", device)\n",
    "model.to(device)\n",
    "training_iter = DataLoader(training_dataset, batch_size=16, shuffle=True)\n",
    "optimizer = AdamW(model.parameters(), lr = 5e-5)\n",
    "# do the visiualiztion\n",
    "animator = d2l.Animator(xlabel='epoch', xlim=[1,num_epoches],\n",
    "                            legend=['train loss','train_start_acc','train_end_acc','valid_loss', 'valid_start_acc', 'valid_end_acc'])\n",
    "num_batches = len(training_iter)\n",
    "for epoch in range(num_epoches):\n",
    "    model.train()\n",
    "    metric = d2l.Accumulator(4)\n",
    "    for j,i in enumerate(training_iter):\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = i['input_ids'].to(device).long()\n",
    "        attention_mask = i['attention_mask'].to(device).long()\n",
    "        start_pi = i['start_positions'].to(device).long()\n",
    "        end_pi = i['end_positions'].to(device).long()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, start_positions = start_pi,\n",
    "                        end_positions = end_pi)\n",
    "        loss = outputs[0]\n",
    "        start_logit = outputs.start_logits\n",
    "        end_logit = outputs.end_logits\n",
    "        #get the one-hot encoding for \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        with torch.no_grad():\n",
    "            metric.add(loss*input_ids.shape[0], d2l.accuracy(start_logit, start_pi),d2l.accuracy(end_logit,end_pi), input_ids.shape[0])\n",
    "            train_loss = metric[0]/ metric[3]\n",
    "            start_acc = metric[1]/metric[3]\n",
    "            end_acc = metric[2]/metric[3]\n",
    "            if (j + 1) % (num_batches // 5) == 0 or j == num_batches - 1:\n",
    "                  animator.add(epoch + (j + 1) / num_batches,\n",
    "                                 (train_loss, start_acc, end_acc, None, None, None))\n",
    "        #if j%10 ==0:\n",
    "    print('/****************** validation part of epoch '+str(epoch)+' ******************/')\n",
    "    valid_ls, valid_start_acc, valid_end_acc = evaluate_accuracy_gpu(model,validing_iter)\n",
    "    animator.add(epoch+1, (None, None, None, valid_ls, valid_start_acc, valid_end_acc))\n",
    "    print(f'epoch {epoch}, loss {train_loss:.3f}, train start acc {start_acc:.3f}, '\n",
    "              f'train end acc {end_acc:.3f}, valid loss {valid_ls:.3f}, valid start acc {valid_start_acc:.3f} '\n",
    "         f' valid_end_acc {valid_end_acc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"./model_saved/\")\n",
    "tokenizer.save_pretrained(\"./model_saved/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the test part:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-12T13:14:19.328332Z",
     "iopub.status.busy": "2021-12-12T13:14:19.327487Z",
     "iopub.status.idle": "2021-12-12T13:14:21.096632Z",
     "shell.execute_reply": "2021-12-12T13:14:21.095311Z",
     "shell.execute_reply.started": "2021-12-12T13:14:19.328286Z"
    }
   },
   "outputs": [],
   "source": [
    "# first load the model in\n",
    "tokenizer_done = DistilBertTokenizerFast.from_pretrained(\"./model_saved/\")\n",
    "model_done = DistilBertForQuestionAnswering.from_pretrained(\"./model_saved/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-12T13:16:53.933593Z",
     "iopub.status.busy": "2021-12-12T13:16:53.93326Z",
     "iopub.status.idle": "2021-12-12T13:16:53.939602Z",
     "shell.execute_reply": "2021-12-12T13:16:53.938724Z",
     "shell.execute_reply.started": "2021-12-12T13:16:53.933559Z"
    }
   },
   "outputs": [],
   "source": [
    ">>> text = r\"\"\"\n",
    "... ðŸ¤— Transformers (formerly known as pytorch-transformers and pytorch-pretrained-bert) provides general-purpose\n",
    "... architectures (BERT, GPT-2, RoBERTa, XLM, DistilBert, XLNetâ€¦) for Natural Language Understanding (NLU) and Natural\n",
    "... Language Generation (NLG) with over 32+ pretrained models in 100+ languages and deep interoperability between\n",
    "... TensorFlow 2.0 and PyTorch.\n",
    "... \"\"\"\n",
    "\n",
    ">>> questions = [\n",
    "...     \"How many pretrained models are available in ðŸ¤— Transformers?\",\n",
    "...     \"What does ðŸ¤— Transformers provide?\",\n",
    "...     \"ðŸ¤— Transformers provides interoperability between which frameworks?\",\n",
    "... ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-12T13:17:37.004573Z",
     "iopub.status.busy": "2021-12-12T13:17:37.004228Z",
     "iopub.status.idle": "2021-12-12T13:17:37.015172Z",
     "shell.execute_reply": "2021-12-12T13:17:37.014078Z",
     "shell.execute_reply.started": "2021-12-12T13:17:37.00454Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_answer(context, query, net,tokenizer_done):\n",
    "    '''\n",
    "    input:\n",
    "        1. context is a string\n",
    "        2. query is a list of question\n",
    "        3. net is the model given by user\n",
    "    Given the original context and question(query),\n",
    "    This function will return an answer for it.\n",
    "    '''\n",
    "    import time\n",
    "    print(context)\n",
    "    #start = time.time()\n",
    "    pred = []\n",
    "    net.eval()\n",
    "    for i, question in enumerate(query):\n",
    "#         #print(i)\n",
    "#         if i==1000:\n",
    "#             break\n",
    "        inputs = tokenizer_done(question,context[i], truncation = True, padding=True,add_special_tokens=True, return_tensors=\"pt\")\n",
    "        input_ids = inputs[\"input_ids\"].tolist()[0]\n",
    "        outputs = net(**inputs)\n",
    "        answer_start_scores = outputs.start_logits\n",
    "        answer_end_scores = outputs.end_logits\n",
    "        # Get the most likely beginning of answer with the argmax of the score\n",
    "        answer_start = torch.argmax(answer_start_scores)\n",
    "        # Get the most likely end of answer with the argmax of the score\n",
    "        answer_end = torch.argmax(answer_end_scores) + 1\n",
    "        # change the ids to token, and token to string\n",
    "        answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end]))\n",
    "        pred.append(answer)\n",
    "        print(f\"Question: {question}\")\n",
    "        print(f\"Answer: {answer}\")\n",
    "    #end = time.time()\n",
    "#     print((end-start)/60)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-12-12T13:17:52.439929Z",
     "iopub.status.busy": "2021-12-12T13:17:52.439533Z",
     "iopub.status.idle": "2021-12-12T13:17:52.57429Z",
     "shell.execute_reply": "2021-12-12T13:17:52.573091Z",
     "shell.execute_reply.started": "2021-12-12T13:17:52.439894Z"
    }
   },
   "outputs": [],
   "source": [
    "prediction_answer = predict_answer(text, questions, model,tokenizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
