{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!mkdir squad\n!wget https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json -O squad/train-v2.0.json\n!wget https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json -O squad/dev-v2.0.json\n!pip install transformers\n!pip install git+https://github.com/d2l-ai/d2l-zh@release  # installing d2l","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-11T11:12:56.367259Z","iopub.execute_input":"2021-12-11T11:12:56.367709Z","iopub.status.idle":"2021-12-11T11:13:26.25465Z","shell.execute_reply.started":"2021-12-11T11:12:56.367637Z","shell.execute_reply":"2021-12-11T11:13:26.25341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader\nimport pandas as pd\nimport numpy as np\nfrom d2l import torch as d2l","metadata":{"execution":{"iopub.status.busy":"2021-12-11T11:13:26.262562Z","iopub.execute_input":"2021-12-11T11:13:26.263101Z","iopub.status.idle":"2021-12-11T11:13:26.952054Z","shell.execute_reply.started":"2021-12-11T11:13:26.263047Z","shell.execute_reply":"2021-12-11T11:13:26.950926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import XLNetTokenizerFast, XLNetForQuestionAnsweringSimple\nimport torch\ntokenizer = XLNetTokenizerFast.from_pretrained('xlnet-base-cased')\nmodel = XLNetForQuestionAnsweringSimple.from_pretrained('xlnet-base-cased')","metadata":{"execution":{"iopub.status.busy":"2021-12-11T11:13:26.954008Z","iopub.execute_input":"2021-12-11T11:13:26.954411Z","iopub.status.idle":"2021-12-11T11:13:34.508155Z","shell.execute_reply.started":"2021-12-11T11:13:26.95432Z","shell.execute_reply":"2021-12-11T11:13:34.507109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#do the data preprocessing\nfrom pathlib import Path\ndef preprocessing_and_read_dataset(path):\n  path = Path(path)\n  data_set = pd.read_json(path) \n  contexts = []\n  questions = []\n  answers = []\n  for article in data_set['data']:\n    paragraphs = article['paragraphs']\n    title = article['title']\n    for paragraph in paragraphs:\n      context = paragraph['context']\n      qas = paragraph['qas']\n      for text in qas:\n        q_id = text['id']\n        q_answer = text['answers']\n        q_isimp = text['is_impossible']\n        q_question = text['question']\n        for ans in q_answer:\n          contexts.append(context)\n          questions.append(q_question)\n          answers.append(ans)\n  return contexts, questions, answers","metadata":{"execution":{"iopub.status.busy":"2021-12-11T11:13:34.511603Z","iopub.execute_input":"2021-12-11T11:13:34.512005Z","iopub.status.idle":"2021-12-11T11:13:34.535101Z","shell.execute_reply.started":"2021-12-11T11:13:34.511957Z","shell.execute_reply":"2021-12-11T11:13:34.533724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_contexts, train_questions, train_answers = preprocessing_and_read_dataset('squad/train-v2.0.json')\nvalid_contexts, valid_questions, valid_answers = preprocessing_and_read_dataset('squad/dev-v2.0.json')","metadata":{"execution":{"iopub.status.busy":"2021-12-11T11:13:34.537012Z","iopub.execute_input":"2021-12-11T11:13:34.537416Z","iopub.status.idle":"2021-12-11T11:13:36.315545Z","shell.execute_reply.started":"2021-12-11T11:13:34.537375Z","shell.execute_reply":"2021-12-11T11:13:36.314319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_encoding = tokenizer(train_contexts, train_questions, truncation=True, padding=True, max_length=512)#do the tokenize with padding and truncation\nvaliding_encoding = tokenizer(valid_contexts, valid_questions, truncation=True, padding=True, max_length=512)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T11:13:36.317285Z","iopub.execute_input":"2021-12-11T11:13:36.317634Z","iopub.status.idle":"2021-12-11T11:15:09.479269Z","shell.execute_reply.started":"2021-12-11T11:13:36.317591Z","shell.execute_reply":"2021-12-11T11:15:09.478225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def add_end_indices(answer, context):\n  '''\n  The given input is the answer dicitionary and corresponding context\n  '''\n  for a, ctext in zip(answer, context):\n    answer_text = a['text']\n    start_idx = a['answer_start']\n    end_idx = start_idx + len(answer_text)\n    # the readme file say that squad answers maybe off by a character or two, to fix this problem\n    if ctext[start_idx:end_idx] == answer_text:\n      a['answer_end'] = end_idx# add the end idx into it\n    elif ctext[start_idx-1:end_idx-1] == answer_text:\n      a['answer_end'] = end_idx-1\n      a['answer_start'] = start_idx-1\n    elif ctext[start_idx-2:end_idx-2] == answer_text:\n      a['answer_end'] = end_idx-2\n      a['answer_start'] = start_idx-2\nadd_end_indices(train_answers,train_contexts)\nadd_end_indices(valid_answers,valid_contexts)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T11:15:09.481177Z","iopub.execute_input":"2021-12-11T11:15:09.48153Z","iopub.status.idle":"2021-12-11T11:15:09.58386Z","shell.execute_reply.started":"2021-12-11T11:15:09.481486Z","shell.execute_reply":"2021-12-11T11:15:09.582943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def token_positions(encoding, answer):\n  start_position = []\n  end_position = []\n  for i in range(len(answer)):\n    #it will return the index of start token and end token\n    start_position.append(encoding.char_to_token(i, answer[i]['answer_start']))\n    end_position.append(encoding.char_to_token(i, answer[i]['answer_end']-1))\n    # if start position is none, answer has been truncated, then we assume it to the max_length\n    if start_position[-1] is None:\n      start_position[-1] = tokenizer.model_max_length\n    if end_position[-1] is None:\n      end_position[-1] = tokenizer.model_max_length\n  encoding.update({\"start_positions\": start_position, \"end_positions\": end_position})\ntoken_positions(training_encoding, train_answers)\ntoken_positions(validing_encoding, valid_answers)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T11:15:09.585436Z","iopub.execute_input":"2021-12-11T11:15:09.585761Z","iopub.status.idle":"2021-12-11T11:15:10.179103Z","shell.execute_reply.started":"2021-12-11T11:15:09.585712Z","shell.execute_reply":"2021-12-11T11:15:10.178015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Squad_v2_Dataset(torch.utils.data.Dataset):\n  '''\n  We need to implement the __init__, __get__item and __len__ function\n  '''\n  def __init__(self, encoding):\n    self.encoding = encoding\n  def __getitem__(self, idx):\n    '''\n    given the idx, return the corresponding key-value pair\n    '''\n    dic = {}\n    for key, value in self.encoding.items():\n      dic[key] = torch.tensor(value[idx],dtype=torch.float)\n    return dic\n  def __len__(self):\n    return len(self.encoding.input_ids)\ntraining_dataset = Squad_v2_Dataset(training_encoding)\nvaliding_dataset = Squad_v2_Dataset(validing_encoding)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T11:15:10.180909Z","iopub.execute_input":"2021-12-11T11:15:10.181444Z","iopub.status.idle":"2021-12-11T11:15:10.195622Z","shell.execute_reply.started":"2021-12-11T11:15:10.181397Z","shell.execute_reply":"2021-12-11T11:15:10.194083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_iter = DataLoader(training_dataset, batch_size=4, shuffle=True)\nvaliding_iter = DataLoader(validing_dataset, batch_size=4, shuffle=False)\nnext(iter(training_iter)), next(iter(validing_iter))","metadata":{"execution":{"iopub.status.busy":"2021-12-11T11:15:10.198267Z","iopub.execute_input":"2021-12-11T11:15:10.202275Z","iopub.status.idle":"2021-12-11T11:15:10.244824Z","shell.execute_reply.started":"2021-12-11T11:15:10.202207Z","shell.execute_reply":"2021-12-11T11:15:10.243763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AdamW\ndef evaluate_accuracy_gpu(net, data_iter, device=None):\n    '''\n    For test iter evaluate the accuracy\n    '''\n    #set to evaluation\n    net.eval()\n    if not device:\n        device = next(iter(net.parameters())).device\n    metric  = d2l.Accumulator(4)# validation loss,total correct num and total prediction\n    for batch in data_iter:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        start_pi = batch['start_positions'].to(device)\n        end_pi = batch['end_positions'].to(device)\n        outputs = net(input_ids, attention_mask=attention_mask, start_positions = start_pi,\n                        end_positions = end_pi)\n        loss = outputs[0]\n        start_logit = outputs.start_logits\n        end_logit = outputs.end_logits\n        metric.add(loss*input_ids.shape[0], d2l.accuracy(start_logit, start_pi),d2l.accuracy(end_logit,end_pi), input_ids.shape[0])\n    return metric[0]/metric[3], metric[1]/metric[3], metric[2]/metric[3]","metadata":{"execution":{"iopub.status.busy":"2021-12-11T11:15:10.248305Z","iopub.execute_input":"2021-12-11T11:15:10.248599Z","iopub.status.idle":"2021-12-11T11:15:10.280197Z","shell.execute_reply.started":"2021-12-11T11:15:10.248565Z","shell.execute_reply":"2021-12-11T11:15:10.279194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nnum_epoches = 3\nprint(\"training on \", device)\nmodel.to(device)\ntraining_iter = DataLoader(training_dataset, batch_size=16, shuffle=True)\noptimizer = AdamW(model.parameters(), lr = 5e-5)\n# do the visiualiztion\nanimator = d2l.Animator(xlabel='epoch', xlim=[1,num_epoches],\n                            legend=['train loss','train_start_acc','train_end_acc','valid_loss', 'valid_start_acc', 'valid_end_acc'])\nnum_batches = len(training_iter)\nfor epoch in range(num_epoches):\n    model.train()\n    metric = d2l.Accumulator(4)\n    for j,i in enumerate(training_iter):\n        optimizer.zero_grad()\n        input_ids = i['input_ids'].to(device).long()\n        attention_mask = i['attention_mask'].to(device).long()\n        start_pi = i['start_positions'].to(device).long()\n        end_pi = i['end_positions'].to(device).long()\n        outputs = model(input_ids, attention_mask=attention_mask, start_positions = start_pi,\n                        end_positions = end_pi)\n        loss = outputs[0]\n        start_logit = outputs.start_logits\n        end_logit = outputs.end_logits\n        #get the one-hot encoding for \n        loss.backward()\n        optimizer.step()\n        with torch.no_grad():\n            metric.add(loss*input_ids.shape[0], d2l.accuracy(start_logit, start_pi),d2l.accuracy(end_logit,end_pi), input_ids.shape[0])\n            train_loss = metric[0]/ metric[3]\n            start_acc = metric[1]/metric[3]\n            end_acc = metric[2]/metric[3]\n            if (j + 1) % (num_batches // 5) == 0 or j == num_batches - 1:\n                  animator.add(epoch + (j + 1) / num_batches,\n                                 (train_loss, start_acc, end_acc, None, None, None))\n        #if j%10 ==0:\n    print('/****************** validation part of epoch '+str(epoch)+' ******************/')\n    valid_ls, valid_start_acc, valid_end_acc = evaluate_accuracy_gpu(model,validing_iter)\n    animator.add(epoch+1, (None, None, None, valid_ls, valid_start_acc, valid_end_acc))\n    print(f'epoch {epoch}, loss {train_loss:.3f}, train start acc {start_acc:.3f}, '\n              f'train end acc {end_acc:.3f}, valid loss {valid_ls:.3f}, valid start acc {valid_start_acc:.3f} '\n         f' valid_end_acc {valid_end_acc:.3f}')","metadata":{"execution":{"iopub.status.busy":"2021-12-11T11:15:10.281883Z","iopub.execute_input":"2021-12-11T11:15:10.282223Z","iopub.status.idle":"2021-12-11T11:15:16.165997Z","shell.execute_reply.started":"2021-12-11T11:15:10.282171Z","shell.execute_reply":"2021-12-11T11:15:16.164307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save_pretrained(\"./model_saved_xlnet/\")\ntokenizer.save_pretrained(\"./model_saved_xlnet/\")","metadata":{},"execution_count":null,"outputs":[]}]}